{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yasirrustam06/All-colab-codes/blob/main/face_mask_detection_Tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Face Mask Detection using yolov5**"
      ],
      "metadata": {
        "id": "xN8c0cpLR2Mc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing the Required Packages....\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SiAOXQT4RpA0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "import shutil\n",
        "import random"
      ],
      "metadata": {
        "id": "hn-XWsV8RyEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVozsqNDbkMI",
        "outputId": "1933ad80-9ba0-4865-f343-623ec5e1c4dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Clone repo, install dependencies and check PyTorch and GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "import torch\n",
        "from IPython.display import Image, clear_output\n",
        "clear_output()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "just drag and drop your dataset into colab...\n",
        "\n",
        "*   and then unzip using below command...\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ljDz1mtWT_KW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q ../face_Data -d ../"
      ],
      "metadata": {
        "id": "NEJPHvSS0ENf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed8a8e89-80c8-423f-a919-8474112afa0b"
      },
      "source": [
        "# Train YOLOv5s on COCO128 for 3 epochs\n",
        "!python train.py --img 640 --batch 2 --epochs 30  --data skin_data.yaml --weights yolov5s.pt --cache"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5s.pt, cfg=, data=skin_data.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=30, batch_size=2, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n",
            "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 âœ…\n",
            "YOLOv5 ðŸš€ v7.0-59-gfdc35b1 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n",
            "\u001b[34m\u001b[1mClearML: \u001b[0mrun 'pip install clearml' to automatically track, visualize and remotely train YOLOv5 ðŸš€ in ClearML\n",
            "\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5 ðŸš€ runs in Comet\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n",
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                 from  n    params  module                                  arguments                     \n",
            "  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              \n",
            "  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                \n",
            "  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   \n",
            "  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
            "  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 \n",
            "  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
            "  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 \n",
            "  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
            "  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 \n",
            "  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 \n",
            " 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              \n",
            " 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n",
            " 13                -1  1    361984  models.common.C3                        [512, 256, 1, False]          \n",
            " 14                -1  1     33024  models.common.Conv                      [256, 128, 1, 1]              \n",
            " 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n",
            " 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n",
            " 17                -1  1     90880  models.common.C3                        [256, 128, 1, False]          \n",
            " 18                -1  1    147712  models.common.Conv                      [128, 128, 3, 2]              \n",
            " 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n",
            " 20                -1  1    296448  models.common.C3                        [256, 256, 1, False]          \n",
            " 21                -1  1    590336  models.common.Conv                      [256, 256, 3, 2]              \n",
            " 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n",
            " 23                -1  1   1182720  models.common.C3                        [512, 512, 1, False]          \n",
            " 24      [17, 20, 23]  1     16182  models.yolo.Detect                      [1, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [128, 256, 512]]\n",
            "Model summary: 214 layers, 7022326 parameters, 7022326 gradients, 15.9 GFLOPs\n",
            "\n",
            "Transferred 343/349 items from yolov5s.pt\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 57 weight(decay=0.0), 60 weight(decay=0.0005), 60 bias\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/face_Data/labels/train.cache... 9 images, 0 backgrounds, 0 corrupt: 100% 9/9 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.0GB ram): 100% 9/9 [00:00<00:00, 200.18it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/face_Data/labels/val.cache... 3 images, 0 backgrounds, 0 corrupt: 100% 3/3 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.0GB ram): 100% 3/3 [00:00<00:00, 64.52it/s]\n",
            "\n",
            "\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.00 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset âœ…\n",
            "Plotting labels to runs/train/exp6/labels.jpg... \n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/train/exp6\u001b[0m\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       0/29      0.51G    0.06391    0.03023          0          2        640: 100% 5/5 [00:02<00:00,  2.18it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  6.11it/s]\n",
            "                   all          3          3    0.00333          1     0.0905     0.0238\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       1/29     0.596G    0.06196    0.03049          0          1        640: 100% 5/5 [00:00<00:00, 10.94it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  7.06it/s]\n",
            "                   all          3          3    0.00333          1      0.124      0.029\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       2/29     0.596G    0.06097    0.02912          0          1        640: 100% 5/5 [00:00<00:00, 10.94it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  7.38it/s]\n",
            "                   all          3          3    0.00333          1     0.0905     0.0181\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       3/29     0.596G    0.06791    0.03199          0          1        640: 100% 5/5 [00:00<00:00, 10.54it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  6.82it/s]\n",
            "                   all          3          3    0.00333          1     0.0905     0.0282\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       4/29     0.596G    0.08573    0.03607          0          4        640: 100% 5/5 [00:00<00:00, 10.54it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  7.69it/s]\n",
            "                   all          3          3    0.00333          1     0.0807     0.0266\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       5/29     0.596G    0.06602    0.03063          0          1        640: 100% 5/5 [00:00<00:00, 11.51it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  7.37it/s]\n",
            "                   all          3          3    0.00333          1     0.0807     0.0266\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       6/29     0.596G     0.0655    0.03077          0          2        640: 100% 5/5 [00:00<00:00, 11.67it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  7.54it/s]\n",
            "                   all          3          3    0.00333          1     0.0807     0.0266\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       7/29     0.596G    0.05667    0.03212          0          2        640: 100% 5/5 [00:00<00:00, 11.05it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  7.95it/s]\n",
            "                   all          3          3    0.00333          1     0.0536     0.0127\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       8/29     0.596G    0.06063    0.03392          0          2        640: 100% 5/5 [00:00<00:00, 11.09it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  7.89it/s]\n",
            "                   all          3          3    0.00333          1     0.0536     0.0127\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "       9/29     0.596G    0.08353    0.03153          0          2        640: 100% 5/5 [00:00<00:00, 10.91it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  7.61it/s]\n",
            "                   all          3          3    0.00333          1     0.0536     0.0127\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      10/29     0.596G    0.06312     0.0353          0          2        640: 100% 5/5 [00:00<00:00, 10.41it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  8.67it/s]\n",
            "                   all          3          3    0.00333          1     0.0151    0.00434\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      11/29     0.596G    0.05815    0.02944          0          1        640: 100% 5/5 [00:00<00:00, 11.00it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  7.53it/s]\n",
            "                   all          3          3    0.00333          1     0.0151    0.00434\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      12/29     0.596G    0.07094    0.03435          0          1        640: 100% 5/5 [00:00<00:00, 11.40it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  8.56it/s]\n",
            "                   all          3          3    0.00333          1     0.0151    0.00434\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      13/29     0.596G    0.05618    0.03114          0          2        640: 100% 5/5 [00:00<00:00, 10.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  7.00it/s]\n",
            "                   all          3          3    0.00333          1     0.0151    0.00434\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      14/29     0.596G    0.06979    0.03241          0          1        640: 100% 5/5 [00:00<00:00, 11.50it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  8.46it/s]\n",
            "                   all          3          3    0.00333          1     0.0151    0.00434\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      15/29     0.596G     0.0666    0.03096          0          2        640: 100% 5/5 [00:00<00:00, 10.89it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  9.00it/s]\n",
            "                   all          3          3    0.00333          1     0.0415     0.0124\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      16/29     0.596G     0.0602    0.03416          0          2        640: 100% 5/5 [00:00<00:00, 10.98it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  9.09it/s]\n",
            "                   all          3          3    0.00333          1     0.0415     0.0124\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      17/29     0.596G    0.06644    0.03485          0          4        640: 100% 5/5 [00:00<00:00, 10.88it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  9.24it/s]\n",
            "                   all          3          3    0.00333          1     0.0415     0.0124\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      18/29     0.596G    0.07787    0.03098          0          1        640: 100% 5/5 [00:00<00:00, 11.24it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  8.36it/s]\n",
            "                   all          3          3    0.00333          1     0.0415     0.0124\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      19/29     0.596G    0.06743    0.03689          0          4        640: 100% 5/5 [00:00<00:00, 11.54it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  8.91it/s]\n",
            "                   all          3          3    0.00333          1     0.0415     0.0124\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      20/29     0.596G    0.05903    0.02823          0          2        640: 100% 5/5 [00:00<00:00, 10.81it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  9.29it/s]\n",
            "                   all          3          3    0.00333          1     0.0415     0.0124\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      21/29     0.596G      0.066    0.03994          0          4        640: 100% 5/5 [00:00<00:00, 10.94it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  8.85it/s]\n",
            "                   all          3          3    0.00333          1     0.0415     0.0124\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      22/29     0.596G    0.05534    0.03195          0          1        640: 100% 5/5 [00:00<00:00, 10.73it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  8.48it/s]\n",
            "                   all          3          3    0.00333          1     0.0415     0.0173\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      23/29     0.596G    0.05634    0.02979          0          2        640: 100% 5/5 [00:00<00:00, 10.81it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  8.38it/s]\n",
            "                   all          3          3    0.00333          1     0.0415     0.0173\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      24/29     0.596G    0.06851    0.03453          0          3        640: 100% 5/5 [00:00<00:00, 11.06it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  8.31it/s]\n",
            "                   all          3          3    0.00333          1     0.0415     0.0173\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      25/29     0.596G      0.047    0.02941          0          1        640: 100% 5/5 [00:00<00:00, 11.58it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  8.49it/s]\n",
            "                   all          3          3    0.00333          1     0.0415     0.0173\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      26/29     0.596G    0.04826    0.02977          0          1        640: 100% 5/5 [00:00<00:00, 11.80it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  8.85it/s]\n",
            "                   all          3          3    0.00333          1     0.0415     0.0173\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      27/29     0.596G    0.05258    0.03204          0          4        640: 100% 5/5 [00:00<00:00, 11.32it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  8.60it/s]\n",
            "                   all          3          3    0.00333          1     0.0415     0.0173\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      28/29     0.596G    0.06468    0.02817          0          2        640: 100% 5/5 [00:00<00:00,  9.99it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  8.16it/s]\n",
            "                   all          3          3    0.00333          1     0.0663     0.0259\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n",
            "      29/29     0.596G     0.0599     0.0291          0          2        640: 100% 5/5 [00:00<00:00, 10.69it/s]\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  8.18it/s]\n",
            "                   all          3          3    0.00333          1     0.0663     0.0259\n",
            "\n",
            "30 epochs completed in 0.008 hours.\n",
            "Optimizer stripped from runs/train/exp6/weights/last.pt, 14.4MB\n",
            "Optimizer stripped from runs/train/exp6/weights/best.pt, 14.4MB\n",
            "\n",
            "Validating runs/train/exp6/weights/best.pt...\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 1/1 [00:00<00:00,  6.37it/s]\n",
            "                   all          3          3    0.00333          1      0.124      0.029\n",
            "Results saved to \u001b[1mruns/train/exp6\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zo3MbtR2Q9lL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights runs/train/exp6/weights/best.pt --img 640 --conf 0.25 --source ../my_photo.jpeg"
      ],
      "metadata": {
        "id": "o-4MHIONQ9nz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b6d149a-0573-4c6d-cae4-2488242c3f17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mdetect: \u001b[0mweights=['runs/train/exp6/weights/best.pt'], source=../my_photo.jpeg, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1\n",
            "YOLOv5 ðŸš€ v7.0-59-gfdc35b1 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
            "image 1/1 /content/my_photo.jpeg: 640x640 (no detections), 12.6ms\n",
            "Speed: 0.6ms pre-process, 12.6ms inference, 0.4ms NMS per image at shape (1, 3, 640, 640)\n",
            "Results saved to \u001b[1mruns/detect/exp7\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Showing the detection result which used in above cell for test\n"
      ],
      "metadata": {
        "id": "vXYiPEp_Tfm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#used opencv for displaying the detected images (which i detect in above cell)\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "image = cv2.imread(\"/content/yolov5/runs/detect/exp3/my_image.jpg\")\n",
        "height, width = image.shape[:2]\n",
        "resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(18, 10)\n",
        "plt.axis(\"off\")\n",
        "plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "J5rBaVdITepJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights runs/train/exp2/weights/best.pt --img 640 --conf 0.25 --source ../video.mp4"
      ],
      "metadata": {
        "id": "WewkHmX2TslA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}